configfile: "config/snake_config.yaml"

include:
    "rules/qc.smk"
include:
    "rules/trimming.smk"
include:
    "rules/alignment.smk"
include:
    "rules/expression.smk"
#include:
#    "rules/dge_analysis.smk"

rule all:
    input:
        "results/read_quality/QC_raw/qcreport_raw.html",
        "results/read_quality/QC_trimmed/qcreport_trimmed.html",
        expand("results/expression/{sample}/compare.stats", sample=config['samples'])

rule all_qc:
    input:
        "results/read_quality/QC_raw/qcreport_raw.html",
        "results/read_quality/QC_trimmed/qcreport_trimmed.html"

rule all_align:
    input:
        expand("results/alignment/{sample}.bam", sample=config['samples'])

rule all_expression:
    input:
        expand("results/expression/{sample}/compare.stats", sample=config['samples'])

#rule all_dge_analysis:


'''
What to do when benchmarking and running alternative tools?
- Multiple rule alls: rename to all_macrogen when doing another pipeline, then get other all_star, etc.
- Each rules file has more than one option, so do it one by one to check.
The problem is that each tool should be tested one by one, maybe, but to not forget it. 
- But maybe hisat+bowtie is better than star+whatever, even if star better than bowtie.
Think on how to do it.
'''